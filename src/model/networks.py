import tensorflow as tf
from model.utils import var_scope
from model.layers import reflectionPadding2D

_init = tf.initializers.random_normal(0, 0.2)


def configure_norm(config):
    norm = config.nn.common.norm
    if norm == 'instance':
        return tf.contrib.layers.instance_norm
    else:
        raise RuntimeError('Unsupported norm ' + norm)


def configure_completion_net(input, config):
    """Configures completion network from config

    :param input: Input tensor
    :param config: Configuration object
    :return:
    """
    cc = config.nn.completion
    return completion_net(input, cc.downsample, cc.channels, configure_norm(config))


@var_scope("completion_net")
def completion_net(input, n_downsample=3, channels=64, norm_layer=tf.contrib.layers.instance_norm):
    """ Defines completion network
    *CompGenerator*
    :param input: input image
    :param n_downsample: how many times size of image should be reduced by half (number of stride convolutions)
    :param channels: number of channes in completion network
    :param norm_layer: norm layer to use
    :return:
    """
    x = input
    x = reflectionPadding2D(x, 3)
    x = tf.layers.conv2d(x, filters=channels, kernel_size=(7, 7), kernel_initializer=_init)
    x = norm_layer(x)
    x = tf.nn.relu(x)

    for i in range(n_downsample):
        mult = 2 ** i
        x = tf.layers.conv2d(x, filters=channels * mult * 2, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer=_init)
        x = norm_layer(x)
        x = tf.nn.relu(x)

    x = reflectionPadding2D(x, 3)
    x = tf.layers.conv2d(x, filters=3, kernel_size=(3, 3), kernel_initializer=_init)
    x = tf.nn.tanh(x)
    return x


def configure_fine_net(input, config):
    """
    Configures fine network from config

    :param input: input tensor
    :param config:
    :return:
    """
    cf = config.nn.fine
    return fine_net(input, cf.downsample, cf.channels, n_blocks=cf.resnet_blocks, norm_layer=configure_norm(config))


@var_scope("fine_net")
def fine_net(input, n_downsample=3, channels=64, n_blocks=9, norm_layer=tf.contrib.layers.instance_norm):
    """
    Fine network. As input takes coarse image generated by completion network + segmentation, and
    tries to reproduce original image

    :param input:
    :param n_downsample:
    :param channels:
    :param n_blocks:
    :param norm_layer:
    :return:
    """

    x = input
    x = reflectionPadding2D(x, 3)
    x = tf.layers.conv2d(x, filters=channels, kernel_size=(7, 7), kernel_initializer=_init)
    x = tf.contrib.layers.instance_norm(x)
    x = tf.nn.relu(x)

    ### downsample
    for i in range(n_downsample):
        mult = 2 ** i
        x = tf.layers.conv2d(x, filters=channels * mult * 2, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer=_init)
        x = norm_layer(x)
        x = tf.nn.relu(x)

    ### resnet blocks
    mult = 2 ** n_downsample
    for i in range(n_blocks):
        with tf.variable_scope("resnet_block_" + str(i)):
            x = resnet_block(x, channels * mult, norm_layer=norm_layer)

    ### upsample
    for i in range(n_downsample):
        mult = 2 ** (n_downsample - i)
        filters = int(channels * mult / 2)
        x = tf.layers.conv2d_transpose(x, filters=filters, kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer=_init)
        x = norm_layer(x)
        x = tf.nn.relu(x)

    x = reflectionPadding2D(x, 3)
    x = tf.layers.conv2d(x, filters=3, kernel_size=(7, 7), kernel_initializer=_init)
    x = tf.nn.tanh(x)
    return x


def configure_multiscale_discriminator(input, config):
    cd = config.nn.discriminator
    return multiscale_discriminator(input, cd.n_discriminators, cd.channels, cd.layers, configure_norm(config))


@var_scope('multiscale_discriminator')
def multiscale_discriminator(input, n_discriminators=2, channels=64, n_layers=3,
                             norm_layer=tf.contrib.layers.instance_norm):
    """ Implementation of multiscale discriminator

    :param input: Input layer (fake or real image)
    :param n_discriminators: number of discriminators, each gets image with half size of the previous
    :param channels:
    :param n_layers: number of layers in discriminator
    :param norm_layer:
    :return: list of results (wgan em distance), list of features (for feature matching)
    """
    input_downsampled = input
    result = []
    result_features = []
    for i in range(n_discriminators):
        with tf.variable_scope("n_layer_discriminator_" + str(i)):
            discriminator, features = n_layer_discriminator(input, channels, n_layers, norm_layer)
            result.append(discriminator)
            result_features.append(features)
            input_downsampled = tf.layers.average_pooling2d(input_downsampled, pool_size=(2, 2), strides=(2, 2),
                                                            padding='same')
    return result, result_features


def n_layer_discriminator(input, channels, n_layers, norm_layer):
    feature_layers = []

    with tf.variable_scope('input_block'):
        x = input
        x = tf.layers.conv2d(x, filters=channels, kernel_size=(4, 4), strides=(2, 2), padding='same', kernel_initializer=_init)
        x = tf.nn.leaky_relu(x, alpha=0.2)
        feature_layers.append(x)

    filters = channels
    for n in range(1, n_layers):
        with tf.variable_scope('layer_' + str(n)):
            filters = min(channels * n * 2, 512)
            x = tf.layers.conv2d(x, filters=filters, kernel_size=(4, 4), strides=(2, 2), padding='same', kernel_initializer=_init)
            x = norm_layer(x)
            x = tf.nn.leaky_relu(x, alpha=0.2)
            feature_layers.append(x)

    with tf.variable_scope('output_block'):
        filters = min(filters * 2, 512)
        x = tf.layers.conv2d(x, filters=filters, kernel_size=(4, 4), padding='same', kernel_initializer=_init)
        x = norm_layer(x)
        x = tf.nn.leaky_relu(x, alpha=0.2)
        feature_layers.append(x)

        x = tf.layers.conv2d(x, filters=1, kernel_size=(4, 4), padding='same', name='final_conv', kernel_initializer=_init)

    return x, feature_layers


def resnet_block(features, channels, norm_layer):
    """ Resnet block used in fine network
    :param features:
    :param channels:
    :param norm_layer:
    :return:
    """
    c = reflectionPadding2D(features, 1)
    c = tf.layers.conv2d(c, filters=channels, kernel_size=(3, 3), kernel_initializer=_init)
    c = norm_layer(c)
    c = tf.nn.relu(c)

    c = reflectionPadding2D(c, 1)
    c = tf.layers.conv2d(c, filters=channels, kernel_size=(3, 3), kernel_initializer=_init)
    c = norm_layer(c)

    result = features + c
    return result
